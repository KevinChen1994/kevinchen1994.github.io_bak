---
title: "Mixtral 8x7B MoEæ¨¡å‹ç¬”è®°"
date: "2024-01-05T01:18:00.000Z"
lastmod: "2024-06-12T09:08:00.000Z"
draft: false
series: []
authors:
  - "é™ˆçŒ›"
tags:
  - "MoE"
categories:
  - "LLM"
summary: "éšç€ Mixtral 8x7B çš„æ¨å‡ºï¼Œä¸€ç§ç§°ä¸ºæ··åˆä¸“å®¶æ¨¡å‹ (Mixed Expert Modelsï¼Œç®€ç§° MoEs) çš„
  Transformer æ¨¡å‹åœ¨å¼€æºäººå·¥æ™ºèƒ½ç¤¾åŒºå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚"
NOTION_METADATA:
  object: "page"
  id: "d99a1952-b7fd-48cd-8182-9c4965664b75"
  created_time: "2024-01-05T01:18:00.000Z"
  last_edited_time: "2024-06-12T09:08:00.000Z"
  created_by:
    object: "user"
    id: "cc08a802-cdc1-4040-b261-957206a41bd5"
  last_edited_by:
    object: "user"
    id: "cc08a802-cdc1-4040-b261-957206a41bd5"
  cover: null
  icon: null
  parent:
    type: "database_id"
    database_id: "8d6a6f9d-5a2c-433b-a560-b744eab9db1a"
  archived: false
  in_trash: false
  properties:
    series:
      id: "B%3C%3FS"
      type: "multi_select"
      multi_select: []
    draft:
      id: "JiWU"
      type: "checkbox"
      checkbox: false
    Created time:
      id: "UBQ%7B"
      type: "created_time"
      created_time: "2024-01-05T01:18:00.000Z"
    authors:
      id: "bK%3B%5B"
      type: "people"
      people:
        - object: "user"
          id: "cc08a802-cdc1-4040-b261-957206a41bd5"
          name: "é™ˆçŒ›"
          avatar_url: "https://s3-us-west-2.amazonaws.com/public.notion-static.com/775523\
            b7-57cf-4c98-8ad8-8777d898666f/notion-avatar-1678713535269.png"
          type: "person"
          person:
            email: "346521888@qq.com"
    custom-front-matter:
      id: "c~kA"
      type: "rich_text"
      rich_text: []
    tags:
      id: "jw%7CC"
      type: "multi_select"
      multi_select:
        - id: "7fe9c3d7-f18a-495a-a55a-3e8a9ab43af2"
          name: "MoE"
          color: "default"
    categories:
      id: "nbY%3F"
      type: "multi_select"
      multi_select:
        - id: "e417d9a1-8454-498a-b9de-502d57e26681"
          name: "LLM"
          color: "gray"
    summary:
      id: "x%3AlD"
      type: "rich_text"
      rich_text:
        - type: "text"
          text:
            content: "éšç€ Mixtral 8x7B çš„æ¨å‡ºï¼Œä¸€ç§ç§°ä¸ºæ··åˆä¸“å®¶æ¨¡å‹ (Mixed Expert Modelsï¼Œç®€ç§° MoEs) çš„
              Transformer æ¨¡å‹åœ¨å¼€æºäººå·¥æ™ºèƒ½ç¤¾åŒºå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚"
            link: null
          annotations:
            bold: false
            italic: false
            strikethrough: false
            underline: false
            code: false
            color: "default"
          plain_text: "éšç€ Mixtral 8x7B çš„æ¨å‡ºï¼Œä¸€ç§ç§°ä¸ºæ··åˆä¸“å®¶æ¨¡å‹ (Mixed Expert Modelsï¼Œç®€ç§° MoEs) çš„
            Transformer æ¨¡å‹åœ¨å¼€æºäººå·¥æ™ºèƒ½ç¤¾åŒºå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚"
          href: null
    Date:
      id: "zYLY"
      type: "date"
      date: null
    Name:
      id: "title"
      type: "title"
      title:
        - type: "text"
          text:
            content: "Mixtral 8x7B MoEæ¨¡å‹ç¬”è®°"
            link: null
          annotations:
            bold: false
            italic: false
            strikethrough: false
            underline: false
            code: false
            color: "default"
          plain_text: "Mixtral 8x7B MoEæ¨¡å‹ç¬”è®°"
          href: null
  url: "https://www.notion.so/Mixtral-8x7B-MoE-d99a1952b7fd48cd81829c4965664b75"
  public_url: "https://kevinchen1994.notion.site/Mixtral-8x7B-MoE-d99a1952b7fd48c\
    d81829c4965664b75"
UPDATE_TIME: "2024-10-18T07:21:46.664Z"
EXPIRY_TIME: "2024-10-18T08:21:43.187Z"

---
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">


## å‰è¨€


å¤§æ¨¡å‹æ—¶ä»£æ¨¡å‹çš„å‚æ•°é‡è¶Šæ¥è¶Šå¤§ï¼ŒGPT3çš„æ¨¡å‹å‚æ•°è¾¾åˆ°äº†175Bï¼Œå„å¤§å‚å•†ä¹Ÿåœ¨ä¸æ–­çªç ´æ¨¡å‹å‚æ•°é‡çš„å¤©èŠ±æ¿ã€‚æ¨¡å‹å‚æ•°é‡å¢å¤§æ˜¾è€Œæ˜“è§çš„å¥½å¤„å°±æ˜¯æ¨¡å‹çš„èƒ½åŠ›è¶Šæ¥è¶Šå¼ºï¼Œå¹¶ä¸”æ¨¡å‹çš„å‚æ•°é‡è¾¾åˆ°ä¸€å®šçš„è§„æ¨¡åï¼Œæ¨¡å‹å°±ä¼šå‡ºç°æ¶Œç°èƒ½åŠ›ï¼ˆEmergent Abilitiesï¼‰ï¼Œè€Œå¸¦æ¥çš„åå¤„ä¹Ÿæ˜¯å¾ˆæ˜æ˜¾çš„ï¼Œé‚£å°±æ˜¯è®­ç»ƒå’Œæ¨ç†çš„ç¡¬ä»¶æˆæœ¬ä¸æ–­å¢åŠ ã€‚


2023å¹´12æœˆï¼ŒMistral AIåœ¨å¼€æºç¤¾åŒºæ‰”äº†ä¸€æ¡ç£åŠ›é“¾æ¥ï¼Œå¼•çˆ†äº†ç¤¾äº¤ç½‘ç»œã€‚Mistral AIåŸºäºæ··åˆä¸“å®¶æ¨¡å‹Mixture of Expertsï¼ˆMoEï¼‰ï¼Œè¯æ˜é€šè¿‡8ä¸ª7Bçš„æ¨¡å‹å°±èƒ½è¶…è¶ŠLLaMA 2 70Bæ¨¡å‹çš„æ•ˆæœï¼Œç”šè‡³éƒ¨åˆ†è¶…è¶Šäº†GPT 3.5çš„æ°´å¹³ã€‚ä¹‹å‰å°±æœ‰äººåˆ†æè¿‡GPT4å°±æ˜¯ä½¿ç”¨8ä¸ªä¸“å®¶æ¨¡å‹ç»„æˆçš„ä¸“å®¶ç³»ç»Ÿï¼Œè¿™ç»™æˆ‘ä»¬å¸¦æ¥äº†å¾ˆå¤šå¯å‘ï¼Œæ˜¯å¦æœªæ¥å¤§æ¨¡å‹æœªæ¥ä¼šæœç€è¿™ä¸ªæ–¹å‘å‘å±•å‘¢ï¼Ÿ


![](https://prod-files-secure.s3.us-west-2.amazonaws.com/d7dbc101-82ce-4f96-ae1a-879bd6c9f3a6/74b12913-f31e-4dca-acca-ccbd24cf586e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45HZZMZUHI%2F20241018%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20241018T072143Z&X-Amz-Expires=3600&X-Amz-Signature=df2c2c3791589dd7d489a5183107d9aa810bcb4fec2758ce72edc656c8f6dc43&X-Amz-SignedHeaders=host&x-id=GetObject)


## Mixtral 8x7Bæ¨¡å‹æ¶æ„


Mixtral 8x7Bä¸LLaMAæ¨¡å‹çš„åŒºåˆ«å°±æ˜¯åœ¨attentionè®¡ç®—ä¸­å°†MLP Layeræ›¿æ¢æˆäº†ä¸€ä¸ªé—¨æ§å±‚å’Œ8ä¸ªä¸“å®¶æ¨¡å‹ï¼Œé€šè¿‡é—¨æ§å±‚ä¼šç»™å‡ºæ¯ä¸ªä¸“å®¶å±‚çš„æƒé‡ï¼Œæ¯ä¸ªtokenä¼šé€‰æ‹©top2çš„ä¸“å®¶è¿›è¡Œè®¡ç®—ï¼Œ è¿™ä½¿å¾—æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„é€Ÿåº¦ç›¸æ¯”äºLLaMA 2 70Bä¼šæ˜¾è‘—æé«˜ã€‚


ä¸è¿‡è¿™é‡Œæœ‰ä¸€ä¸ªè¯¯åŒºï¼Œé‚£å°±æ˜¯æ¨¡å‹è™½ç„¶å«8x7Bï¼Œä½†æ˜¯æ¨¡å‹çš„å‚æ•°å¹¶ä¸æ˜¯56Bï¼Œå› ä¸ºåœ¨æ¯ä¸ªå±‚ä¸­åªæœ‰ä¸“å®¶å±‚æ˜¯ç‹¬ç«‹å­˜åœ¨çš„ï¼Œå…¶ä»–éƒ¨åˆ†å¦‚attentionæ˜¯æƒé‡å…±äº«çš„ï¼Œæ‰€ä»¥æ¨¡å‹çš„å‚æ•°é‡åœ¨47Bå·¦å³ã€‚


![](https://prod-files-secure.s3.us-west-2.amazonaws.com/d7dbc101-82ce-4f96-ae1a-879bd6c9f3a6/0775893f-4189-40b0-a47f-cf4a45d07bff/moe.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45HZZMZUHI%2F20241018%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20241018T072143Z&X-Amz-Expires=3600&X-Amz-Signature=1393c2de91a67b40af5586e13148902aa80b0055c4dd44cf039457af65ae7deb&X-Amz-SignedHeaders=host&x-id=GetObject)


## ä¸“å®¶æ¨¡å—ç»†èŠ‚


å› ä¸ºMixtral 8x7Bæ¨¡å‹æ¶æ„ä¸LLaMAç›¸æ¯”åªæœ‰FFNå—ä¸åŒï¼Œæ‰€ä»¥æˆ‘ä»¬åªå…³æ³¨è¿™å—çš„ç»†èŠ‚ã€‚


æˆ‘ä¹‹å‰çœ‹è¿‡ä¸€ä¸ªä»£ç è§£è¯»ï¼Œä»–è¯´MoEå±‚æ˜¯å…ˆè®¡ç®—æ‰€æœ‰ä¸“å®¶çš„è¾“å‡ºï¼Œç„¶ååœ¨é€‰æ‹©æ¯ä¸ªtokenå¯¹åº”çš„ä¸“å®¶ï¼Œå…¶å®è¿™æ ·çš„è¯´æ³•æ˜¯é”™è¯¯çš„ã€‚å› ä¸ºå¦‚æœæ¯æ¬¡éƒ½è®¡ç®—æ‰€æœ‰ä¸“å®¶çš„è¾“å‡ºï¼Œé‚£å°±ä¸èƒ½ä½“ç°å‡ºMoEæ¨¡å‹çš„ä¼˜åŠ¿äº†ï¼Œ8ä¸ªæ¨¡å‹éƒ½è®¡ç®—çš„è¯ï¼Œä½ çš„è®¡ç®—é‡æ˜¯å¾ˆå¤§çš„ï¼Œé‚£ä¹ˆä½ çš„è€—æ—¶ä¹Ÿä¼šå¢åŠ ï¼Œèµ·ä¸åˆ°æé€Ÿçš„æ•ˆæœã€‚æ‰€ä»¥æ­£ç¡®çš„ç†è§£æ˜¯é€šè¿‡é—¨æ§å±‚æ¥é€‰æ‹©ä¸“å®¶ï¼Œç„¶ååªæœ‰å¯¹åº”çš„2ä¸ªä¸“å®¶ä¼šè¿›è¡Œå‰å‘è®¡ç®—ï¼Œè¿™æ ·å°±èµ·åˆ°äº†å‡å°‘è®¡ç®—é‡å’Œæé€Ÿçš„æ•ˆæœã€‚


é¦–å…ˆè¾“å…¥ç»è¿‡attentionè®¡ç®—åï¼Œç»è¿‡æ®‹å·®è¿æ¥ã€Normå±‚ä¼šè¾“å…¥è¿›è¡Œä¸“å®¶å±‚ï¼Œä¸“å®¶å±‚ç”±é—¨æ§å±‚å’Œ8ä¸ªä¸“å®¶æ„æˆã€‚é—¨æ§å±‚å…¶å®å°±æ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå…¶è¾“å‡ºç»“æœå†ç»è¿‡softmaxå‡½æ•°å¾—åˆ°å„ä¸“å®¶çš„æƒé‡ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©æƒé‡æ’åçš„top2ä½œä¸ºå½“å‰tokenè¦ä½¿ç”¨çš„ä¸“å®¶ã€‚ç„¶åå¯¹è¿™ä¸¤ä¸ªä¸“å®¶çš„æƒé‡é‡æ–°è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¾—åˆ°è¿™ä¸¤ä¸ªä¸“å®¶çš„æƒé‡ï¼Œåœ¨å‰å‘è®¡ç®—çš„è¿‡ç¨‹ä¸­ï¼Œtop2çš„ä¸“å®¶çš„è¾“å‡ºç»“æœä¼šä¸å…¶å¯¹åº”çš„æƒé‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œæœ€ç»ˆæˆ‘ä»¬å°±èƒ½å¾—åˆ°æ•´ä¸ªè¾“å…¥ä½¿ç”¨ä¸åŒçš„ä¸“å®¶çš„ç»“æœã€‚


æ•´ä¸ªæµç¨‹æ˜¯æ¯”è¾ƒç®€å•çš„ï¼Œå¯èƒ½å®¹æ˜“å¼„æ··çš„åœ°æ–¹åœ¨äºæ¨¡å‹çš„è¾“å…¥æ˜¯**tokenç²’åº¦**çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨è®¡ç®—æƒé‡å’Œé€‰æ‹©ä¸“å®¶çš„è¿‡ç¨‹ä¸­ï¼Œéƒ½æ˜¯ä»¥æ¯ä¸ªtokenä¸ºè§†è§’çš„ã€‚ä¹Ÿå°±æ˜¯æ¯ä¸€ä¸ªtokenéƒ½ä¼šè®¡ç®—ä¸“å®¶æƒé‡ï¼Œå¹¶é€‰æ‹©top2çš„ä¸“å®¶è®¡ç®—å‰å‘ç»“æœï¼Œæœ€ç»ˆå¾—åˆ°çš„æ˜¯æ•´ä¸ªè¾“å…¥çš„ç»“æœã€‚è¿™ä¸ªè¿‡ç¨‹ç»“åˆä»£ç çœ‹ä¼šæ›´åŠ æ¸…æ™°ã€‚


## ä¸“å®¶æ¨¡å—ä»£ç æ³¨é‡Š


ä¸‹è¾¹çš„ä»£ç æ˜¯ä¸“å®¶æ¨¡å—çš„å®ç°æ–¹æ³•ï¼Œæˆ‘å¯¹é‡è¦éƒ¨åˆ†å†™ä¸Šäº†æ³¨é‡Šï¼Œå¯ä»¥ç»“åˆæ³¨é‡Šè¿›è¡Œç†è§£ã€‚


```python
class MixtralSparseMoeBlock(nn.Module):
    """
    This implementation is
    strictly equivalent to standard MoE with full capacity (no
    dropped tokens). It's faster since it formulates MoE operations
    in terms of block-sparse operations to accomodate imbalanced
    assignments of tokens to experts, whereas standard MoE either
    (1) drop tokens at the cost of reduced performance or (2) set
    capacity factor to number of experts and thus waste computation
    and memory on padding.
    """

    def __init__(self, config):
        super().__init__()
        self.hidden_dim = config.hidden_size
        self.ffn_dim = config.intermediate_size
        self.num_experts = config.num_local_experts
        self.top_k = config.num_experts_per_tok

        # gating
        self.gate = nn.Linear(self.hidden_dim, self.num_experts, bias=False)

        self.experts = nn.ModuleList([MixtralBLockSparseTop2MLP(config) for _ in range(self.num_experts)])

    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:
        """ """
        # ç”±attentionè®¡ç®—åè¾“å‡ºçš„hidden_statesä½œä¸ºè¾“å…¥
        batch_size, sequence_length, hidden_dim = hidden_states.shape
        # å°†hidden_statesæ„å»ºæˆä¸€ä¸ªäºŒç»´çš„å½¢çŠ¶ï¼Œç”¨äºå¤„ç†æ¯ä¸€ä¸ªtoken
        hidden_states = hidden_states.view(-1, hidden_dim)
        # router_logits: (batch * sequence_length, n_experts)
        # é€šè¿‡é—¨æ§æ¥ç”Ÿæˆè·¯ç”±ï¼Œç”¨æ¥å†³å®šæ¯ä¸€ä¸ªtokenç”±å“ªäº›ä¸“å®¶å¤„ç†
        router_logits = self.gate(hidden_states)

        # é€šè¿‡softmaxè®¡ç®—æ¯ä¸€ä¸ªä¸“å®¶å¯¹äºæ¯ä¸ªtokençš„å¤„ç†æƒé‡
        routing_weights = F.softmax(router_logits, dim=1, dtype=torch.float)
        # é€‰å–æ¯ä¸ªtokençš„å‰top_kä¸ªä¸“å®¶å’Œå…¶å¯¹åº”çš„æƒé‡  selected_experts: (batch * sequence_length, top_k)
        routing_weights, selected_experts = torch.topk(routing_weights, self.top_k, dim=-1)
        # å¯¹æ¯ä¸€ä¸ªtokenå¯¹åº”çš„ä¸“å®¶çš„æƒé‡å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å…¶æƒé‡ä¹‹å’Œä¸º1
        routing_weights /= routing_weights.sum(dim=-1, keepdim=True)
        # we cast back to the input dtype
        routing_weights = routing_weights.to(hidden_states.dtype)

        # final_hidden_statesç”¨æ¥å­˜å‚¨æ¯ä¸ªtokenå¯¹åº”çš„ä¸“å®¶ç»“æœï¼Œåˆå§‹å€¼ä¸º0
        final_hidden_states = torch.zeros(
            (batch_size * sequence_length, hidden_dim), dtype=hidden_states.dtype, device=hidden_states.device
        )

        # One hot encode the selected experts to create an expert mask
        # this will be used to easily index which expert is going to be sollicitated
        # ä½¿ç”¨one hotç¼–ç æ¥ä»£è¡¨æ¯ä¸ªtokenä½¿ç”¨å“ªäº›ä¸“å®¶
        # one hot: (batch * sequence_length, top_k, num_experts) => expert_mask: (num_experts, top_k, batch * sequence_length)
        # è¿™æ ·åšçš„å¥½å¤„å°±æ˜¯ï¼Œç”¨ä¸“å®¶çš„è§†è§’ï¼Œæ¯æ¬¡éå†åªéœ€è¦éå†æ¯ä¸ªä¸“å®¶æ‰€éœ€è¦å¤„ç†çš„tokenå³å¯ï¼Œå¦åˆ™éœ€è¦éå†æ¯ä¸ªtokenä½¿ç”¨äº†å“ªä¸ªä¸“å®¶ï¼Œå‰å‘çš„æ¬¡æ•°éšç€æ–‡æœ¬çš„é•¿åº¦çº¿æ€§å¢åŠ ã€‚
        expert_mask = torch.nn.functional.one_hot(selected_experts, num_classes=self.num_experts).permute(2, 1, 0)

        # Loop over all available experts in the model and perform the computation on each expert
        for expert_idx in range(self.num_experts):
            expert_layer = self.experts[expert_idx]
            # idxä»£è¡¨å½“å‰ä¸“å®¶ä½œä¸ºtop1éœ€è¦è´Ÿè´£çš„tokenç´¢å¼•ã€ä½œä¸ºtop2éœ€è¦è´Ÿè´£çš„tokençš„ç´¢å¼•
            # top_xä»£è¡¨å½“å‰ä¸“å®¶è´Ÿè´£çš„tokençš„ç´¢å¼•ä½ç½®ã€‚
            idx, top_x = torch.where(expert_mask[expert_idx])

            # å¦‚æœtop_xä¸­æ²¡æœ‰1ï¼Œåˆ™ä»£è¡¨å½“å‰ä¸“å®¶ä¸è´Ÿè´£ä»»ä½•tokenï¼Œå°±è·³è¿‡è¿™ä¸ªä¸“å®¶
            if top_x.shape[0] == 0:
                continue

            # in torch it is faster to index using lists than torch tensors
            top_x_list = top_x.tolist()
            idx_list = idx.tolist()

            # Index the correct hidden states and compute the expert hidden state for
            # the current expert. We need to make sure to multiply the output hidden
            # states by `routing_weights` on the corresponding tokens (top-1 and top-2)
            # æ ¹æ®ç´¢å¼•ä»è¾“å…¥çš„éšå‘é‡ä¸­å–å¾—å¯¹åº”çš„å‘é‡ï¼Œä¼ å…¥åˆ°ä¸“å®¶æ¨¡å‹ä¸­è¿›è¡Œå‰å‘è®¡ç®—
            current_state = hidden_states[None, top_x_list].reshape(-1, hidden_dim)
            current_hidden_states = expert_layer(current_state) * routing_weights[top_x_list, idx_list, None]

            # However `index_add_` only support torch tensors for indexing so we'll use
            # the `top_x` tensor here.
            # å°†å½“å‰ä¸“å®¶æ¨¡å‹çš„è¾“å‡ºå†™å…¥åˆ°é¢„å…ˆå®šä¹‰å¥½çš„final_hidden_statesä¸­
            final_hidden_states.index_add_(0, top_x, current_hidden_states.to(hidden_states.dtype))
        final_hidden_states = final_hidden_states.reshape(batch_size, sequence_length, hidden_dim)
        return final_hidden_states, router_logits
```


> ğŸš€ å¦‚æœä¸Šè¾¹çš„ä»£ç çœ‹ä¸€éä¸å¥½ç†è§£çš„è¯ï¼Œå¯ä»¥çœ‹ä¸€ä¸‹ä¸‹è¾¹çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œç»“åˆdebugçš„è¾“å‡ºçœ‹æ›´å®¹æ˜“ç†è§£ã€‚


ä¸‹å›¾ä¸­çš„ä»£ç ä»£è¡¨äº†é€‰æ‹©ä¸“å®¶çš„ç®€å•é€»è¾‘ï¼Œå‡è®¾å½“å‰æœ‰10ä¸ªtokenå’Œ4ä¸ªä¸“å®¶ï¼Œæ¯ä¸ªtokené€‰æ‹©2ä¸ªä¸“å®¶ã€‚expert_maskè¾“å‡ºçš„ç»“æœå°±æ˜¯æ¯ä¸ªä¸“å®¶éœ€è¦è´Ÿè´£çš„tokenï¼Œæˆ‘ä»¬æ‹†å¼€æ¥çœ‹ã€‚


åœ¨ç¬¬ä¸€æ¬¡éå†çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éå†çš„æ˜¯ç¬¬ä¸€ä¸ªä¸“å®¶ï¼Œå¯ä»¥çœ‹åˆ°ä»–æ˜¯ä¸€ä¸ª(2, 10)çš„çŸ©é˜µï¼Œç¬¬ä¸€è¡Œä»£è¡¨äº†å½“å‰ä¸“å®¶ä½œä¸ºtop1è´Ÿè´£çš„tokenï¼Œç¬¬äºŒè¡Œä»£è¡¨äº†å½“å‰ä¸“å®¶ä½œä¸ºtop2è´Ÿè´£çš„tokenã€‚


æˆ‘ä»¬é€šè¿‡`torch.where(expert_mask)` æ¥è¿›è¡Œè§£æè¿™ä¸ªç»“æœï¼Œå¾—åˆ°çš„`idx` ä¸­çš„0ä»£è¡¨äº†å½“å‰ä¸“å®¶ä½œä¸ºtop1éœ€è¦è´Ÿè´£çš„tokenï¼Œ1ä»£è¡¨äº†å½“å‰ä¸“å®¶ä½œä¸ºtop2éœ€è¦è´Ÿè´£çš„tokenï¼Œå¯¹åº”çš„`top_x` åˆ™ä»£è¡¨äº†å½“å‰ä¸“å®¶è´Ÿè´£çš„tokençš„ç´¢å¼•ä½ç½®ï¼Œå°†`idx`å’Œ`top_x` ç»„åˆå°±å¾—åˆ°äº†å½“å‰ä¸“å®¶ä½œä¸ºtop1ã€top2è´Ÿè´£çš„tokençš„ç´¢å¼•ï¼Œä¾‹å¦‚(0,2)ã€(0,8)ã€(0,9)ã€(1,0)ã€(1,1)ã€(1,5)ï¼Œå¯¹åº”çš„æ„æ€å°±æ˜¯å½“å‰ä¸“å®¶ä½œä¸ºtop1è´Ÿè´£çš„tokenç´¢å¼•ä¸º2ã€8ã€9ï¼Œå½“å‰ä¸“å®¶ä½œä¸ºtop2è´Ÿè´£çš„tokenç´¢å¼•ä¸º0ã€1ã€5ã€‚


![](https://prod-files-secure.s3.us-west-2.amazonaws.com/d7dbc101-82ce-4f96-ae1a-879bd6c9f3a6/7a072245-b5a2-42a6-92be-0d87ff5bf77c/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45HZZMZUHI%2F20241018%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20241018T072143Z&X-Amz-Expires=3600&X-Amz-Signature=a574d9e65e9b018a71dc9e1a60fb1046d5f3519dedc4a9b634955e29cd62f87d&X-Amz-SignedHeaders=host&x-id=GetObject)


## æ›´å¤šé˜…è¯»èµ„æ–™


[Mistral AIå®˜ç½‘å¯¹Mixtral 8x7Bä»‹ç»](https://mistral.ai/news/mixtral-of-experts/)


[huggingface æ··åˆä¸“å®¶æ¨¡å‹ (MoE) è¯¦è§£](https://huggingface.co/blog/zh/moe)


[è¿™ç¯‡æ–‡ç« æå‡ºçš„å…³äºMixtral 8x7Bçš„å‡ ä¸ªé—®é¢˜å¾ˆæœ‰æ„æ€ï¼Œæ¯”å¦‚è®­ç»ƒçš„æ—¶å€™å‡ ä¸ªä¸“å®¶åŒæ—¶è®­ç»ƒã€8ä¸ªä¸“å®¶çš„è´¡çŒ®åº¦æ€ä¹ˆæ ·](https://zhuanlan.zhihu.com/p/674751021)

